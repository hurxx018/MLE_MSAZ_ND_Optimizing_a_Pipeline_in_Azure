# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure Machine Learning (ML) Nanodegree program. 
In this project, our interest is to build a classification model that predicts 
if a customer subscribes a term deposit (variable y) using the bank marketing data.
We built an ML pipeline using Azure ML SDK in Python. 
A HyperDrive is used to determine optimal hyperparameters for a logistic regression model 
that is implemented using scikit-learn library. 
The two hyperparameters: the inverse of regularization (C) and the maximum number of iterations (max-iter) 
were tested in this project.
The HyperDrive found out a pair of C~0.19 and max-iter=500.
The logistic regression model trained with the two hyperparameters showed the accuracy of ~0.91.
This optimized logistic regression model was then compared to the optimal model of VotingEnsemble from an Azure AutoML run.
The accuracy of the VotingEnsemble model was ~0.92, which showed slight improvement compared to the logistic regression obtained through HyperDrive.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

The bank marketing data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution 
(https://archive.ics.uci.edu/ml/datasets/bank+marketing). 
We build a classification model that predicts if the client will subscribe a term deposit (variable y).

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

The Azure AutoML pipeline found out the best performing model of VotingEnsemble with the accuracy of ~0.92.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

The bank marketting data is downloaded from the open source. 
Our Hyperdrive pipeline uses the logistic regression algorithm to build a classification model.
The Hyperdrive pipeline determines the two optimal hyperparameter of 
the inverse of regularization (C) and the maximum number of iterations (max-iter).
The hyperparameters were randomly sampled using RandomParameterSampling. 
The BanditPolicy is used to apply the early stopping. 

**What are the benefits of the parameter sampler you chose?**

RandomParameter Sampling picks up proper values in given ranges of parameters.

**What are the benefits of the early stopping policy you chose?**

BanditPolicy seems to be efficient of choosing the early stopping point.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

The AutoML found out the VotingEnsemble model. Its accuracy is about 0.92.

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

The logistic regression model of C~0.19 and max-iter=500 showed the accuracy of ~0.91. 
The VotingEnsemble model showed the accuracy of ~0.92. 
The accuracy difference is only ~0.01, which is quite small.
The VotingEnsemble model might be able to find out a submodel which characterizes features that the logistic regression misses.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

I will adjust parameters of BanditPolicy and see how the accuracy varies depending on these parameters. 
For example, evaluation_interval can be 100, which allows a model to be more trained before it is compared with the current best model. 
Some algorithm might need more data points to find out its optimal parameters.

## Proof of cluster clean up

The compute cluster is programmatically deleted at the end of the notebook.
